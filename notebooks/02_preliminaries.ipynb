{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e119f3ee-bdc9-42fb-a2f9-9c3a52aad5b1",
   "metadata": {},
   "source": [
    "# Preliminaries  \n",
    "\n",
    "**Overview**  \n",
    "This section provides the essential survival skills needed before diving into deep learning. It covers how to manipulate and preprocess data, the linear algebra and calculus concepts that underlie neural networks, the use of automatic differentiation, basic probability for reasoning under uncertainty, and how to effectively use documentation. These fundamentals ensure you can follow the technical content of later chapters with confidence.  \n",
    "<br>  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59fab77-35fd-49b1-befa-3f18c8d2e68c",
   "metadata": {},
   "source": [
    "## A. Data Manipulation  \n",
    "\n",
    "**Recap**  \n",
    "This section introduces tensors, the core data structure in PyTorch. A tensor is just a container for numbers in one or more dimensions. We can create them, manipulate them with operations, automatically broadcast shapes when combining arrays of different sizes, save memory efficiently, and convert between PyTorch and other Python objects like NumPy.  \n",
    "\n",
    "**Vocab**  \n",
    "- **Tensor**: A general container for numbers in 1D (vector), 2D (matrix), or higher dimensions.  \n",
    "- **Broadcasting**: Expanding smaller arrays automatically to match larger shapes during operations.  \n",
    "\n",
    "**Notes**  \n",
    "- Tensors are arrays of numbers: 1D = vector, 2D = matrix, higher = tensor.  \n",
    "- Tensors support math operations (add, subtract, multiply, divide) applied elementwise.  \n",
    "- Broadcasting lets smaller tensors expand to match larger shapes automatically.  \n",
    "- In-place operations (`a.add_(b)`) save memory but overwrite values directly.  \n",
    "- Tensors can be converted to/from NumPy arrays or Python scalars, sharing memory in the process.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93917ce0-64be-4859-a8f1-405e95051524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vector v:\n",
      " tensor([0, 1, 2])\n",
      "\n",
      "Matrix M after in-place add with broadcasting:\n",
      " tensor([[1., 2., 3.],\n",
      "        [1., 2., 3.],\n",
      "        [1., 2., 3.]])\n",
      "\n",
      "Result (new tensor, not in-place):\n",
      " tensor([[1., 2., 3.],\n",
      "        [1., 2., 3.],\n",
      "        [1., 2., 3.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a vector and a matrix\n",
    "v = torch.arange(3)          # [0, 1, 2]\n",
    "M = torch.ones((3, 3))       # 3x3 of ones\n",
    "\n",
    "# Broadcasting: vector expands to match matrix shape\n",
    "result = M + v\n",
    "\n",
    "# In-place operation: overwrite to save memory\n",
    "M.add_(v)   # modifies M directly\n",
    "\n",
    "print(\"Original vector v:\\n\", v)\n",
    "print(\"\\nMatrix M after in-place add with broadcasting:\\n\", M)\n",
    "print(\"\\nResult (new tensor, not in-place):\\n\", result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
